# 제 1원칙 사고방식(First Principles Thinking)으로 배우는 얼굴 인식 프로젝트 워크북

이 워크북은 **"AI에게 지시를 내리는 관리자"**로서 이 프로젝트의 본질을 이해하고, 효과적인 의사결정을 내릴 수 있도록 돕기 위해 작성되었습니다.

복잡한 현상을 가장 기초적인 진실(First Principles)로 분해하고, 거기서부터 다시 쌓아 올리는 방식으로 학습합니다.

---

## 1. 디지털 시각의 본질 (Computer Vision)

**질문:** 컴퓨터는 어떻게 세상을 "보는"가?

*   **현상**: 카메라 앱을 켜면 내 얼굴이 화면에 나옵니다.
*   **제 1원칙 분해**:
    1.  **빛 (Light)**: 현실 세계의 광자가 렌즈를 통과합니다.
    2.  **센서 (Sensor)**: 광자는 디지털 신호(전기)로 변환됩니다.
    3.  **데이터 (Matrix)**: 컴퓨터에게 이미지는 **숫자들의 행렬(Matrix)**일 뿐입니다.
    4.  **픽셀 (Pixel)**: 각 숫자는 0(검은색)부터 255(흰색)까지의 밝기를 나타냅니다. 컬러 이미지는 Red, Green, Blue 3개의 숫자가 합쳐진 것입니다.

*   **관리자의 통찰**:
    *   AI가 "얼굴을 못 찾아요"라고 할 때, "조명이 너무 어두워서 숫자가 0에 가까운가?" 또는 "해상도가 낮아서 숫자의 정보량이 부족한가?"라고 의심할 수 있어야 합니다.
    *   **핵심 용어**: `Pixel`, `RGB`, `Resolution`, `Frame Rate(FPS)`

---

## 2. 얼굴 탐지의 본질 (Face Detection)

**질문:** 컴퓨터는 숫자 덩어리에서 어떻게 "얼굴"을 찾아내는가?

*   **현상**: 화면 속 내 얼굴 주위에 네모 박스가 쳐집니다.
*   **제 1원칙 분해**:
    1.  **패턴 (Pattern)**: 얼굴은 보편적인 패턴이 있습니다. (눈 두 개 아래 코, 그 아래 입).
    2.  **학습 (Learning)**: 수백만 장의 사진을 통해 "이런 숫자 배열이 얼굴이다"라는 확률 통계를 만들어냅니다.
    3.  **추론 (Inference)**: AI 모델은 들어오는 이미지를 훑으며 "여기 얼굴일 확률이 99%야"라고 판단합니다.
    4.  **좌표 (Bounding Box)**: 확률이 높은 영역의 위치(x, y, width, height)를 반환합니다.

*   **관리자의 통찰**:
    *   탐지가 안 된다면? -> "모델이 학습한 데이터와 내 환경(조명, 각도, 마스크 착용)이 너무 다른가?"
    *   오탐지(Ghost)가 생긴다면? -> "배경의 패턴이 얼굴과 비슷한 숫자 배열을 가지고 있는가?"
    *   **조절 변수**: `Confidence Threshold` (확신이 몇 % 이상일 때만 얼굴로 인정할 것인가?)

---

## 3. 웹 대시보드의 본질 (State & Interaction)

**질문:** 정적인 파이썬 코드가 어떻게 "실시간" 화면을 보여주는가?

*   **현상**: 웹 페이지에서 카메라 화면이 계속 움직입니다.
*   **제 1원칙 분해**:
    1.  **루프 (Loop)**: 프로그램은 멈추지 않고 계속 돕니다 (While Loop).
    2.  **갱신 (Refresh)**: 루프가 한 번 돌 때마다 1) 카메라에서 사진 한 장 찍기 -> 2) 얼굴 찾기 -> 3) 화면에 그림 그리기 -> 4) 웹 페이지에 덮어쓰기를 반복합니다.
    3.  **상태 (State)**: "카메라 켜짐/꺼짐" 같은 정보는 루프가 다시 돌 때 기억하고 있어야 합니다.

*   **관리자의 통찰**:
    *   화면이 버벅거린다면? -> "한 번의 루프(1~4단계)를 처리하는 데 시간이 너무 오래 걸리는구나."
    *   해결책은? -> "얼굴 찾는 AI를 좀 더 가벼운 걸로 바꾸거나, 이미지 크기를 줄여서 처리할 숫자를 줄여야겠다."

---

## 4. AI 관리자(User)의 역할

**질문:** 나는 AI에게 무엇을 지시해야 하는가?

*   **현상**: 코드는 AI가 짜지만, 결과물의 품질은 내가 결정합니다.
*   **제 1원칙 분해**:
    1.  **명확한 목표 (Objective)**: "얼굴을 찾아줘" (X) -> "웹캠 720p 해상도에서 마스크 쓴 사람의 얼굴도 0.5초 안에 박스를 쳐줘" (O)
    2.  **제약 조건 (Constraint)**: "컴퓨터가 느려지지 않게 처리해줘."
    3.  **피드백 루프 (Iterative Process)**: 결과물을 보고 원인을 추론하여 수정 지시를 내려야 합니다.

*   **학습 체크리스트**:
    - [ ] `OpenCV`가 이미지를 어떻게 읽어오는지 이해했는가? (NumPy array)
    - [ ] `Face Detection` 모델(MTCNN 등)이 입력으로 무엇을 받고(Image), 출력으로 무엇을 뱉는지(Box coordinates) 아는가?
    - [ ] `Streamlit`이 화면을 어떻게 갱신하는지(Rerun) 이해했는가?

---
*이 문서는 프로젝트 진행 상황에 따라 업데이트됩니다.*
